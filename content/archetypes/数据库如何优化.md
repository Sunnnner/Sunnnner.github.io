---
title: "数据库如何优化"
date: 2019-02-04T10:52:21+08:00
draft: true
# weight: 1
# aliases: ["/first"]
tags: ["python"]
author: "whitek"
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
description: "Desc Text."
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
cover:
    image: "<image path/url>" # image path/url
    alt: "<alt text>" # alt text
    caption: "<text>" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: true # only hide on current single page
editPost:
    URL: "https://github.com/Sunnnner/Sunnnner.github.io/content"
    Text: "Suggest Changes" # edit text
    appendFilePath: true # to append file path to Edit link
---

优化SQL语句

通过添加索引进行优化

优化Order by

有两种方式如下：

（1）索引优化：对by后的列添加索引，从而大达到优化的目的。

（2）where+order by 的组合优化：通过where进行限制后在进行order by

优化limit

优化子查询

2.优化数据库结构

  1、优化insert语句

      禁用索引，禁用唯一性检查，使用一条insert插入多条语句。

  2、优化update语句

      使用一个update语句同时做多个更新。

  3、优化delete语句

      删除一条记录的时间与索引的数量成正比。删除一个表的所有行，使用truncate table Tbname 而不要使用delete from table

Django如何优化

1利用标准数据库优化技术：索引, Django建立实体的时候，支持给字段添加索引，具体参考Django.db.models.Field.db_index。

2了解Django的QuerySets：QuerySets是有缓存的，一旦取出来，它就会在内存里呆上一段时间，尽量重用它

3数据库的工作就交给数据库本身计算，别用Python处理：使用 filter and exclude 过滤不需要的记录，这两个是最常用语句，相当是SQL的where。使用annotate对数据库做聚合运算。不要用python语言对以上类型数据过滤筛选，同样的结果，python处理复杂度要高，而且效率不高， 白白浪费内存。使用原生的SQL语句：

4如果需要就一次性取出你所需要的数据：

单一动作（如：同一个页面）需要多次连接数据库时，最好一次性取出所有需要的数据，减少连接数据库次数。此类需求推荐使用QuerySet.select_related() 和 prefetch_related()。使用QuerySet.count()代替len(queryset),虽然这两个处理得出的结果是一样的，但前者性能优秀很多。同理判断记录存在时，QuerySet.exists()比if queryset实在强得太多了。

5 懂减少数据库的连接数：

使用 QuerySet.update() 和 delete()，这两个函数是能批处理多条记录的，适当使用它们事半功倍；如果可以，别一条条数据去update delete处理。

使用 Redis 进行缓存

使用异步 Worker 进行写库操作

高并发问题

：1，悲观锁；2，乐观锁

使用场景：

并发量高的时候使用悲观锁，

缺点：加锁消耗资源

并发量低的时候使用乐观锁，

缺点：乐观锁循环耗费时间。
秒杀问题,一件商品多人抢购如何处理

获取第一位的数据其他人均不满足

说一下事务四大特性和隔离级别

ACID

原子性（Atomicity） 要么全部完成，要么都不成功

一致性(Consistency) 几个并行执行的事务，其执行结果必须与按照某一舒徐串执行的结果相一致

隔离性(Isolation) 事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须市透明的

持久性(Durability) 对于任意已提交事务，系统必须保证该事务对数据库的改变不被丢失，即使数据库出现故障；

隔离级别

脏读 在一个事务处理过程里读取了另一个未提交的事务中的数据

不可重复读 在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，

虚读 是事务非独立执行时发生的一种现象
　　
现在来看看MySQL数据库为我们提供的四种隔离级别：

　　① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。

　　② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。

　　③ Read committed (读已提交)：可避免脏读的发生。

　　④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。

redis的数据类型和使用场景

字符串(str)， 哈希(hash) 列表(list) 集合(set) 有序集合(zset)

一万件商品如何按价格排序取前十个

使用快速排序

```python
def partition(A, p, r):
x = A[r]
i = p - 1
for j in range(p, r):
if A[j] <= x:
i = i + 1
A[i], A[j] = A[j], A[i]
A[i + 1], A[r] = A[r], A[i + 1]
return i + 1

def quickSort(A, p, r):
if p < r:
q = partition(A, p, r)
quickSort(A, p, q - 1)
quickSort(A, q + 1, r)

A = […]

quickSort(A, 0, 9999)
print(A[:-9])
```

redis考数据类型和使用场景,比如list啥时候用,

redis 七个使用场景https://www.cnblogs.com/NiceCui/p/7794659.html

还有MySQL有哪些数据库引擎,有什么区别

ISAM：ISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数要远大于更新的次数

MyISAM：MyISAM是MySQL的ISAM扩展格式和缺省的数据库引擎。

InnoDB：InnoDB数据库引擎都是造就MySQL灵活性的技术的直接产品，这项技术就是MYSQL+API

MEMORY: MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。

InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。

MyISAM：插入数据快，空间和内存使用比较低。

MEMORY：所有的数据都在内存中，数据的处理速度快，但是安全性不高

https://blog.csdn.net/t146lla128xx0x/article/details/78737290

```python
[“1”,”2”,”10”],列表里是字符型数值,如何按数字大小给列表排序
list1 = []
a = [“1”,”2”,”10”]
for i in a:
b = int(i)
list1.append(b)
print(sorted(list1, reverse=True))
```

Python2和3的区别

print不再是语句，而是函数

在Python 3中，没有旧式类，只有新式类

原来1/2（两个整数相除）结果是0，现在是0.5了

新的字符串格式化方法format取代%

xrange重命名为range

!=取代 < >

long重命名为int

except Exception, e变成except (Exception) as e

exec变成函数

爬虫好像问scrapy和scrapy_redis有什么区别

还有scrapy爬虫的执行流程,当场手写

看完我说的你在百度django和爬虫的面试题

RESTfromework问得也挺多

apiview和viewset有啥关系

问rest是啥
